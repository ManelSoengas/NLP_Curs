{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjzsAKUUtwuYGYpd5Cbu86",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ManelSoengas/NLP_Curs/blob/main/NLP_Chapter_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generació de text**\n",
        "\n",
        "---\n",
        "Els models de transformador s'utilitzen per resoldre tot tipus de tasques de NLP, Processament del Llenguatge Natural.\n"
      ],
      "metadata": {
        "id": "AvFTIN4k8FL4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stop-mHB77iL",
        "outputId": "e96bc70a-577d-4156-998d-952b386d6ed0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'Sóc docent, especialitzat en tecnologia i intel·ligència artificial. Faré una xerrada en relació a comprendión de la historia de la historia.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\")\n",
        "generator(\"Sóc docent, especialitzat en tecnologia i intel·ligència artificial. Faré una xerrada en relació a\")\n",
        "\n",
        "# No s'especifica un model concret"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
        "generator(\n",
        "    \"I'm teacher, and work at\",\n",
        "    max_length=30,\n",
        "    num_return_sequences=2,\n",
        ")\n",
        "# Especificant un model, longitut màxima i nombre de oracions\n",
        "# El model ha estat entrenat en anglés, per utilitzar altres idiomes\n",
        "# cal utilitzar models multi-lingues o d'un idioma específic."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNclfRBe91Kb",
        "outputId": "02665532-d489-4865-d1d4-349f1a9b92be"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': \"I'm teacher, and work at school. I can't remember what type of jobs I do. Why don't I have to work, or do\"},\n",
              " {'generated_text': \"I'm teacher, and work at that.\\n\\nA few months after I received a tweet from the Daily Mail saying that my son had killed my\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}